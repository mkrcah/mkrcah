<!DOCTYPE html>
<html lang="en">
<head>
        <title>marcel.is: How a newline can ruin your Hive</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="http://marcel.is/theme/css/main.css" type="text/css" />
        <link href="http://marcel.is/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="marcel.is ATOM Feed" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://marcel.is/css/ie.css"/>
                <script src="http://marcel.is/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://marcel.is/css/ie6.css"/><![endif]-->

</head>

<body>
<h1>How a newline can ruin your Hive
</h1>
<p class="date">May 2015 </p>
<article>
    <p>If you do not fully understand how Hive/Impala stores your data, it might cost you badly.</p>
<p>I've learnt the hard way.</p>
<h2>Symptom #1: Weird values in ingested Hive table</h2>
<p>You double-checked with <code>select distinct(gender) from customers</code> that the <code>gender</code> column in your source RDBMS really contains only values <code>male</code>, <code>female</code> and <code>NULL</code>. However, when you ingest the table into Hive (maybe with <a href="http://sqoop.apache.org/">Apache Sqoop</a> or <a href="https://github.com/datadudes/cornet">Cornet</a>) and run the check there,  you see that weird values have creeped in:</p>
<div class="highlight"><pre><span></span>&gt; select distinct(gender) from customers;  // Run in Hive/Impala
+-----------------+
| gender          |
+-----------------+
| NULL            |
| CA 94304        |
| male            |
| Page Mill Road  |
| female          |
+-----------------+
</pre></div>


<h2>Symptom #2: Inconsistent size of ingested Hive table</h2>
<p>You check with <code>select count(*) from customers</code> that the table in your RDBMS table has <code>156,010</code> rows.  You ingest the table into Hive and BAM! All of a sudden there are 14 more customers.</p>
<p>Maybe the business is doing great and you gained 14 customers before you started the ingestion? Wondering, you check the source table size again.</p>
<p>Still <code>156,010</code>.</p>
<h2>Symptom #3: Weird data when copied from another Hive table</h2>
<p>This one is by far the most strange one.</p>
<p>You already have the <code>customers</code> table ingested in Hive. Values in the <code>gender</code> column look fine. The table has correct size of <code>156,010</code>. All is fine.</p>
<p>You do some data cleaning with SQL and copy the result into a new table as follows:</p>
<div class="highlight"><pre><span></span>CREATE TABLE customers_superclean
AS SELECT name, coalesce(gender, &#39;unknown&#39;) FROM customers;
</pre></div>


<p>You check the size of the new table. BAM! 25 new customers in there. Impossible!</p>
<h2>No errors, no warnings</h2>
<p>Neither Hive, Impala nor Sqoop gave you any error or warning. You have no idea what's going on. Somewhere at the back of your head, you start questioning the whole Hadoop infrastructure. You feel like the cool stuff you do all day with the data has been compromised.</p>
<h2>Cause: Hive delimiters present in the data</h2>
<p>All these problems can occur if the ingested data contains characters that Hive uses to delimit fields and rows. Typically, these are newlines. For instance, let's assume that the <code>customers</code> table in the source RDBMS contains the following data (notice the newline in the first street name):</p>
<table>
<thead>
<tr>
<th>gender</th>
<th>street</th>
</tr>
</thead>
<tbody>
<tr>
<td>male</td>
<td>Page Mill Road<code>\n</code>CA 94304</td>
</tr>
<tr>
<td>female</td>
<td>Great America Parkway</td>
</tr>
</tbody>
</table>
<p>If one naively ingests this data into a Hive table using the default settings (a text file with rows delimited by <code>\01</code> and fields delimited by newlines), the data gets broken. Look at the corresponding delimited file in HDFS:</p>
<div class="highlight"><pre><span></span>male\01Page Mill Road
CA 94304
female\01Great America Parkway
</pre></div>


<p>When Hive/Impala reads from this file, it finds three customers instead of two. The additional customer is of gender <code>CA 94304</code> and has no street specified. On top of that, the street field of the first customer misses the postal code.</p>
<h2>Particularly interesting case: Copying binary data to text file</h2>
<p>Assume that the Hive table called <code>customers</code> uses Avro or Parquet for data storage and that the data contains newlines. Querying the <code>customers</code> table directly via Hive or Impala works as expected. However, let's create a new table as follows:</p>
<div class="highlight"><pre><span></span>CREATE TABLE customers_superclean
AS SELECT gender, street FROM CUSTOMERS;
</pre></div>


<p>The problem with this command is that the new table is backed by a newline-delimited text file. An Avro/Parquet record which contains a newline will be split into two records in the new table. Symptom #3 is born.</p>
<h2>Solution 1: Use binary storage formats like Avro or Parquet</h2>
<p>If possible, use binary storage for your Hive tables, for instance <a href="https://avro.apache.org/">Apache Avro</a> or <a href="http://parquet.apache.org/">Apache Parquet</a>. Since these formats do not use dedicated characters to split a file into records and fields, Hive/Impala can read data with special characters properly.</p>
<p>Also, Avro and Parquet make it possible to safely copy records from one Hive table to another. For instance, checkout the following command which copies data to a Parquet table:</p>
<div class="highlight"><pre><span></span>CREATE TABLE customers_superclean STORED AS parquet
AS SELECT gender, street FROM customers;
</pre></div>


<p>The Parquet storage will ensure that even if  data in the <code>customers</code> table contains newlines or another delimiters, the data will be properly copied and interpreted in the new table.</p>
<h2>Solution 2: Ensure the delimited text file does not contain Hive delimiters</h2>
<p>When ingesting data into a delimited text file, you have to ensure that the file does not contain characters that Hive uses to split data into rows and fields. In general, there are two options to achieve this:</p>
<ul>
<li>Remove Hive delimiters from the data before ingestion. If you use Sqoop, there are handy parameters which can do that for you. Checkout the <a href="https://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_importing_data_into_hive">Sqoop docs</a> and look for <code>--hive-drop-import-delims</code> and  <code>--hive-delims-replacement</code> parameters.</li>
<li>Use custom Hive delimiters that are not present in the data. Unused <a href="http://en.wikipedia.org/wiki/ASCII#ASCII_control_characters">non-printable characters</a> are good candidates, for instance <code>\01</code> or <code>\02</code>. You can instruct Hive <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-RowFormat,StorageFormat,andSerDe">to use custom delimiters</a> as follows:</li>
</ul>
<div class="highlight"><pre><span></span>CREATE TABLE customers
ROW FORMAT DELIMITED
  LINES TERMINATED BY &#39;\002&#39;
  FIELDS TERMINATED BY &#39;\001&#39;;
</pre></div>


<p>Happy ingesting!</p>
</article>
<p class="footer">
  <a href="/connect">subscribe</a>&nbsp;&nbsp;
  <a href="/home">home</a></p>

    <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
    try {
        var pageTracker = _gat._getTracker("UA-53104817-1");
    pageTracker._trackPageview();
    } catch(err) {}</script>
</body>

<script src="//load.sumome.com/" data-sumo-site-id="924bf5462a207a11a5b1bf06354a5a37d9933836e3f385242ee6df941c42f69a" async="async"></script>
</html>