<!DOCTYPE html>
<html lang="en">
<head>
        <title>marcel.is: Analyze your Elastic MapReduce data with Python, Pandas and scikit-learn</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="http://marcel.is/theme/css/main.css" type="text/css" />
        <link href="http://marcel.is/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="marcel.is ATOM Feed" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://marcel.is/css/ie.css"/>
                <script src="http://marcel.is/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://marcel.is/css/ie6.css"/><![endif]-->

</head>

<body>
<h1>Analyze your Elastic MapReduce data with Python, Pandas and scikit-learn
</h1>
<p class="date">August 2014 </p>
<article>
    <p>What a great time it is nowadays for data geeks!</p>
<p>We have Pandas and Scikit-learn - fantastic Python stack for data analysis. On top of that we have IPython and IPython Notebook - powerful coding, documentation and visualization layer for experimenting.</p>
<p>Then we have the whole Hadoop stack with an amazingly fast Impala SQL query engine. We don't even have to build the Hadoop cluster in-house, we just choose the size and spin up a cluster via Amazon AWS and we're done.</p>
<p><strong>And now guys in Cloudera made <a href="https://github.com/cloudera/impyla">Impyla</a> - Python connector to Impala.</strong> And of course, they didn't forget to pack in an Impala connector for Pandas! How great is that?!</p>
<p>So, if you want to connect Pandas to Impala on Elastic MapReduce (EMR), here is how.</p>
<h2>5 steps to connect Pandas to remote Impala</h2>
<h3>Prerequisites</h3>
<p>Install the awesome Pandas, Scikit-learn and IPython stack if you haven't done that already.</p>
<h3>Step 1: Install Impyla</h3>
<div class="highlight"><pre><span></span>$ pip install impyla
</pre></div>


<h3>Step 2: Create an SSH tunnel to Amazon EMR so you can access Impala from localhost</h3>
<div class="highlight"><pre><span></span>$ ssh -L 12345:localhost:21050 your_user_name@your_node.compute.amazonaws.com
</pre></div>


<p>The Impala query engine runs on port 21050 on your Hadoop master node. For security reasons, this port is not accessible from the outside.</p>
<p>This shell command will open up the port 12345 on your local machine and forward it to the port 21050 on the Hadoop master node where the Impala query engine listens. (Of course, you can choose whatever port you want, it doesn't have to be 12345.)</p>
<h3>Step 3: Connect Impyla to Impala via the tunnel</h3>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">impala.dbapi</span> <span class="kn">import</span> <span class="n">connect</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conn</span> <span class="o">=</span> <span class="n">connect</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;localhost&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">12345</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">cur</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
</pre></div>


<p>Notice that we are connecting to <code>localhost:12345</code> which is (securely) forwarded to Impala on Amazon EMR.</p>
<h3>Step 4: Query Impala and convert the result into Pandas dataframe</h3>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">impala.util</span> <span class="kn">import</span> <span class="n">as_pandas</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">cur</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s1">&#39;SELECT * FROM customers LIMIT 500&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">as_pandas</span><span class="p">(</span><span class="n">cur</span><span class="p">)</span>
</pre></div>


<p>Note that the query result must be transported from remote cluster to your localhost. If the result is large, the download might take a while. You might want to check out the network traffic monitor on your system to see when the download is complete.</p>
<h3>Step 5. Enjoy Hadoop data in Pandas</h3>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;gender&#39;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;lifetime_value&#39;</span><span class="p">])</span>
</pre></div>


<h2>Bonus: Impala with scikit-learn API</h2>
<p>By the way, guys at Cloudera are now busy with implementing scikit-learn API in Impyla. They <a href="http://blog.cloudera.com/blog/2014/04/a-new-python-client-for-impala/">already have</a> alpha implementation of linear regression, logistic regression and SVM ready. I'm quite excited where all this is going...</p>
</article>
<p class="footer">
  <a href="/connect">subscribe</a>&nbsp;&nbsp;
  <a href="/home">home</a></p>

    <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
    try {
        var pageTracker = _gat._getTracker("UA-53104817-1");
    pageTracker._trackPageview();
    } catch(err) {}</script>
</body>

</html>