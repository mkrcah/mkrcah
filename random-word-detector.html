<!DOCTYPE html>
<html lang="en">
<head>
        <title>marcel.is: How to automatically detect random text in web registration forms</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="http://marcel.is/theme/css/main.css" type="text/css" />
        <link href="http://marcel.is/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="marcel.is ATOM Feed" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://marcel.is/css/ie.css"/>
                <script src="http://marcel.is/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://marcel.is/css/ie6.css"/><![endif]-->

</head>

<body>
<h1>How to automatically detect random text in web registration forms
</h1>
<p class="date">July 2014 </p>
<article>
    <p>I came across an interesting problem a couple of days ago. A friend of mine runs quite a large website with a lot of users registering on their web. The problem is that there are users which are lazy to enter proper information so they just enter random text, as this for example:</p>
<p><img alt="Example of randomly typed words" src="http://marcel.is/images/random-text.png" /></p>
<p>Since the correct registration information is crucial to their business, he would like to have a solution which would detect such random text automatically.</p>
<p>It would be very useful for him to have a tool which would check all data gathered from registration forms and mark rows which look like  random text. He calls this <em>false user registrations</em>. Also, it would be interesting to have an online detector which would notify the customer-care team if such a false registration is submitted.</p>
<p>Although there are many approaches to this problem, I was curious if such problem can be solved algorithmically. In particular, <strong>I was curious what would be the most simple solution that would be useful in 80% of the cases.</strong> The reason is that when I am presented with a (data) problem, I always find it very effective to start with the most simple solution first. And often these solutions turn out to be satisfactory enough.</p>
<p>Anyway, I was first tempted to go with supervised algorithms, like Naive Bayes classifier for example. However, I realized that it would be much more interesting to come up with an unsupervised algorithm, which would identify random words automatically without any prior knowledge. <strong>Just give the algorithm a list of words and it gives you back words from the list which look random.</strong> Such solution would also be practical from the business perspective since you can immediately identify suspicious registrations in a sea of production data.</p>
<p>So here is a description of a very simple - yet surprisingly effective -  unsupervised solution to this challenge. Based on frequency-analysis of character bigrams.</p>
<h2>Before we dive in, let's the see results</h2>
<p>For the sake of simplicity, I focused on the field of the registration form that contains a customer name. To mock up production data, I took the 2000 most common names in US and added 20 random texts on top of the list. I got <a href="https://raw.githubusercontent.com/mkrcah/random-text-detector/master/data/names-input.txt">this list of words</a>, which I gave as input to the algorithm. (The order of words doesn't matter.)</p>
<p>What the algorithm does is to compute a <em>suspicious score</em> for each word. The higher the score, the more suspicious (i.e. random) the word looks when compared to the rest of the words.</p>
<p>If you run the algorithm, you get <a href="https://raw.githubusercontent.com/mkrcah/random-text-detector/master/data/names-output-adjusted-idf.txt">this list of words sorted by a suspicious score</a>. I marked the 20 random words with an asterix, so I can quickly evaluate quality of the result.</p>
<p>We see that the algorithm is pretty effective: <strong>the top 10 words with the highest suspicious score (above 25.0) consist of random words only.</strong> Actually, the top 16 words consist of 15 random words and only one regular name - <em>guadalupe</em>.</p>
<p>The five random words which didn't make it to the top 20 include <em>tyrwereh</em> (#23), <em>qwerpo</em> (#43) and <em>sfert</em> (#422). However, I'm ok with the low scores here, because these words don't look very random to me anyway :)</p>
<p>I have made also an interactive version of the algorithm, it is <a href="http://random-text-detector.herokuapp.com">available here</a>. Go ahead and give it a try. <em>(Note that it might take up to 10 seconds to load the page because the Heroku node might need to wake up.)</em></p>
<h2>How it works</h2>
<p>If you look at a random word, e.g. <em>sdfjtwd</em>, you see a lot of rare combinations of characters like  <em>sd</em> or <em>ft</em> or <em>jt</em>. If you look at a  word <em>dustin</em>, there is no combination of characters which strikes you are rare. Maybe <em>st</em>, but that's about it.</p>
<p>A combination of two adjacent characters in a word is called a character bigram. So <em>sd</em>, <em>ft</em> and <em>jt</em> are all bigrams of the word <em>sdfjtwd</em>. (By the way, there are also <em>word-bigrams</em> which are adjacent words in a sentence.)</p>
<p>What you want to do to detect random text is the following:</p>
<ol>
<li>Compute a score for each bigram. This score should be high if the bigram is rare among all given words. The score should be low if the bigram is very common among given words.</li>
<li>Compute suspicious score of a given word as a sum of all bigram scores that are contained in the word.</li>
</ol>
<h2>Step 1 - Compute bigram scores</h2>
<p>Consider the words <em>aabaa</em>, <em>abbb</em> and <em>ababa</em> for example. Let's compute for each bigram how many times it occurs in each word and also how many words in total contain this bigram:</p>
<table>
<thead>
<tr>
<th>Word / Bigram</th>
<th>aa</th>
<th>ab</th>
<th>ba</th>
<th>bb</th>
</tr>
</thead>
<tbody>
<tr>
<td>aabaa</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>-</td>
</tr>
<tr>
<td>abb</td>
<td>-</td>
<td>1</td>
<td>-</td>
<td>1</td>
</tr>
<tr>
<td>ababa</td>
<td>-</td>
<td>2</td>
<td>2</td>
<td>-</td>
</tr>
<tr>
<td><strong>Total words containing the bigram</strong></td>
<td><strong>1</strong></td>
<td><strong>3</strong></td>
<td><strong>2</strong></td>
<td><strong>1</strong></td>
</tr>
</tbody>
</table>
<p>We see that the bigram <em>aa</em> occurs twice in the word <em>aabaa</em>, while bigram <em>bb</em> doesn't occur at all in <em>aabaa</em>. Also, we see that the bigram <em>ab</em> is the most common bigram (used in all 3 words) and the bigrams <em>aa</em> and <em>bb</em> are the most rare (used only in one word).</p>
<p>Now we know which bigrams are rare and which are common in the dataset. We just need to translate it into a score.</p>
<p>The most popular metric for this purpose is the <a href="http://en.wikipedia.org/wiki/Tfâ€“idf">inverse document frequency (IDF)</a>. For a given bigram <span class="math">\(b\)</span>, the IDF is computed as</p>
<div class="math">$$ \{IDF}(b) = \log\frac{N}{n_b}, $$</div>
<p>where <span class="math">\(N\)</span> is the total number of words (in our case <span class="math">\(N=3\)</span>), and <span class="math">\(n_b\)</span> is the number of words which contain the bigram <span class="math">\(b\)</span>.</p>
<p>In our example of words <em>aabaa</em>, <em>abbb</em> and <em>ababa</em>, the IDFs are as follows:</p>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>aa</th>
<th>ab</th>
<th>ba</th>
<th>bb</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">\(n_b\)</span></td>
<td>1</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td><span class="math">\(\{IDF}(b)\)</span></td>
<td>1.1</td>
<td>0.0</td>
<td>0.4</td>
<td>1.1</td>
</tr>
</tbody>
</table>
<p>This is exactly what we need: The most common bigram (<em>ab</em>) has zero IDF, while the most rare bigrams (<em>aa</em> and <em>bb</em>) have highest IDF.</p>
<p>By the way, to see the IDFs of all bigrams from our data of 2020 words, click <a href="https://raw.githubusercontent.com/mkrcah/random-text-detector/master/data/names-idf-standard.txt">here</a>.</p>
<h2>Step 2 - Sum up bigram scores</h2>
<p>To get the suspicious score for a given word, we just need to sum up IDFs of all bigrams occurring in a word:</p>
<table>
<thead>
<tr>
<th>Word / Bigram</th>
<th>aa</th>
<th>ab</th>
<th>ba</th>
<th>bb</th>
<th>Suspicious score (sum of IDFs)</th>
</tr>
</thead>
<tbody>
<tr>
<td>aabaa</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>-</td>
<td><strong>2.6</strong> = 2 * 1.1 + 1 * 0.0 + 1 * 0.4</td>
</tr>
<tr>
<td>abb</td>
<td>-</td>
<td>1</td>
<td>-</td>
<td>1</td>
<td><strong>1.1</strong> = 1 * 0.0 + 1 * 1.1</td>
</tr>
<tr>
<td>ababa</td>
<td>-</td>
<td>2</td>
<td>2</td>
<td>-</td>
<td><strong>0.8</strong> = 2 * 0.0 + 2 * 0.4</td>
</tr>
<tr>
<td><strong>IDF</strong></td>
<td><strong>1.1</strong></td>
<td><strong>0.0</strong></td>
<td><strong>0.4</strong></td>
<td><strong>1.1</strong></td>
<td></td>
</tr>
</tbody>
</table>
<p>We see that the word <em>aabaa</em> with a score of 2.6 is the most suspicious word out of our fabricated example.</p>
<p>If you use this algorithm to compute suspicious score on our 2020 words, you get <a href="https://raw.githubusercontent.com/mkrcah/random-text-detector/master/data/names-output-standard-idf.txt">this result</a>. Looks ok, but take a look at positions #9, #11 and #13. <em>Christopher</em> and <em>Jefferson</em> are regular names but they have very high suspicious scores (e.g. higher than <em>lkjwqer</em>, <em>erwtrepo</em> and others).</p>
<p>Can we improve the algorithm?</p>
<h2>Improve the algorithm with adjusted-IDF</h2>
<p>The problem with <em>Christpoher</em> or <em>Jefferson</em> is that they are long and contain a lot of common bigrams. The sum of IDFs of these common bigrams is higher that the sum of IDFs of fewer but more rare bigrams.</p>
<p>To overcome this, we can adjust the IDF formula to return lower score for common bigrams. One of many possible options is to use the following formula:</p>
<div class="math">$$ \text{IDF}_\{adj}(b) = \log\frac{\max_c(n_c)}{n_b}, $$</div>
<p>where the <span class="math">\(\max_c(n_c)\)</span> term is just the number of occurrences of the most common bigram. Using this formula, the bigram score should be zero for the most common bigram and almost zero for very common bigrams.</p>
<p>To see the adjusted-IDFs for the bigram in our sample of 2020 words, click <a href="https://raw.githubusercontent.com/mkrcah/random-text-detector/master/data/names-idf-adjusted.txt">here</a>. You can see that scores of very common bigrams decreased from 2.5 to 0.5, while the score of most rare bigram remain above 5. <em>(You can experiment and tweak this formula more in order to fit your data. Apart from logarithm, you might also consider <a href="http://en.wikipedia.org/wiki/Exponential_distribution">different  functions</a>)</em></p>
<p>The adjusted-IDF is the score that I used to arrive at the <a href="https://github.com/mkrcah/random-text-detector/raw/master/data/names-output-adjusted-idf.txt">results</a> presented in the beginning of the article.</p>
<h2>Grab the source code here</h2>
<p>I put the source code (Scala) on <a href="https://github.com/mkrcah/random-text-detector">github</a>. It tried to make it simple to get the tool up and running on your local machine (either in batch-mode or in server-mode with API). Also, it should be possible to deploy code to <a href="http://random-text-detector.herokuapp.com">Heroku</a> without any code changes.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</article>
<p class="footer"><a href="/home">home</a>&nbsp;&nbsp;<a href="/connect">connect</a></p>

    <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
    try {
        var pageTracker = _gat._getTracker("UA-53104817-1");
    pageTracker._trackPageview();
    } catch(err) {}</script>
</body>
</html>